---
layout: post
title: "1. 线性模型"
description: "线性模型"
categories: [机器学习]
tags: [机器学习]
comments: true
---
# 目录：

* Kramdown table of contents
{:toc .toc}

线性模型一般用于**回归**和**分类**

# 一、线性回归

![]({{ site.url }}/assets/images/machinelearning/linear_02.jpg){:height="30%" width="30%"}

如图所示，回归主要是完成对数据的拟合。

## 回归模型

> 对数据进行线性拟合

样本参数维度为$$d$$，样本数量维度是$$n$$

1. 针对单个样本

$$ y_i = a(x_i) = w^T x_i = w_0 + w_1 x_{i,1} + \cdots + w_d x_{i,d}  
= \begin{pmatrix}w_0 & w_1 & \cdots & w_d \end{pmatrix} \begin{pmatrix} 1 \\ x_{i,1} \\ \vdots \\ x_{i,d} \end{pmatrix}$$

2. 针对$$n$$个样本

$$ Y = a(X) = Xw 
= \begin{pmatrix} w_0 + w_1 x_{1,1} + \cdots + w_d x_{1,d} \\w_0 + w_1 x_{2,1} + \cdots + w_d x_{2,d} \\ \vdots \\ w_0 + w_1 x_{n,1} + \cdots + w_d x_{n,d}\end{pmatrix}
= \begin{pmatrix}1 & x_{11} & \cdots & x_{1d} \\ 1 & x_{21} & \cdots & x_{2d} \\ \vdots \\ 1 & x_{n1} & \cdots & x_{nd} \\ \end{pmatrix} 
$$

## 损失函数

> 对线性拟合效果进行评估

换句话说，如何去选择最优的拟合直线。

线性回归中最常使用的是**最小二乘法（OLS）**，也称为平方损失函数。

1. 最小二乘法 

$$
\begin{eqnarray}
L(w) & = & \frac{1}{2n} \sum_{i=1}^n[a(x_i)-y_i]^2  \\
& = & \frac{1}{2n} \sum_{i=1}^n[w_0 + w_1 x_{i,1} + \cdots + w_d x_{i,d}-y_i]^2\\\\
& = & \frac{1}{2n} \sum_{i=1}^n[w^T x_i-y_i]^2\\
& = & \frac{1}{2n} \begin{pmatrix}w^T x_1-y_1 & \cdots & w^T x_n-y_n \end{pmatrix} \begin{pmatrix}w^T x_1-y_1 \\ \cdots \\ w^T x_n-y_n \end{pmatrix} \\
& = & \frac{1}{2n} \begin{bmatrix}Xw-Y \end{bmatrix}^T \begin{bmatrix} Xw-Y \end{bmatrix}\\
& = & \frac{1}{2n} \begin{Vmatrix}Xw-Y \end{Vmatrix}\\
\end{eqnarray}
$$





参考文献：
