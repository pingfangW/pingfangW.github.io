---
layout: post
title: "机器学习系列课程-深度学习导论"
description: "深度学习"
categories: [机器学习]
tags: [机器学习, 深度学习]
redirect_from:
  - /2018/10/23/
---

# 目录

* Kramdown table of contents
{:toc .toc}

# 正文

Advanced machine learning specialization 机器学习专业化进阶

## 一、线性模型

$$ \sqrt[3] {\frac x y} $$

$$ {\frac 1 l)\|| Xw - y||\^2 $$

![]({{ site.url }}/assets/images/machinelearning/linear_01.jpg)

如上图所示，用直线进行分类。

x,y

回归和分类。均方误差，损失函数

在分类中的应用，y=-1,1

y = 1,2,...,k 多类

判断效果好坏：accuracy loss, Iverson bracket。其实就是看预测结果正确所占的比重。

但是这个指标有两个缺点：在优化过程中一般使用梯度去计算损失函数，而这个损失函数没有梯度，其次是无法计算置信度。

可以用损失函数替代 

a(x) = sign(w^Tx)

交叉熵（cross entropy）

二元/多元

梯度：

终止条件，既可以判断wt-1和wt之间的差是不是足够小，也可以判断损失函数的值的变化是不是变小，还有就是看梯度向量的模是不是接近于0.

有很多问题值得探讨，比如怎么去初始化w0，如何选择步幅eta_t，什么时候停止，如何去估计梯度。

什么情况下，线性模型的analytical solution和MSE loss有效：

训练集和测试集。

交叉训练（cross-validation)训练多次，但像深度神经网络在多个GPU上仍可能训练很多周，训练很多次是不太可行的，一般就选一个测试集。在数据量比较大的情况下，还是具有代表性的。

使用惩罚项的原因是：

在没有过度拟合的情况下，系数的数值一般会小一些。

因此把这个特点看做是特征，认为过度拟合的模型会有较大的权重，而好的模型没有较大的权重。

因此为了解决过度拟合问题，对大的权重进行惩罚。

这样总觉得不对，会不会导致前后结果差别很大？ 比如可能8次方的系数原先很大，然后惩罚以后8次方就被毙了，这种情况怎么说

这里主要是集中在在众多的特征中选择重要的特征。要和另外一种情况做区分：就是所有的特征都有用，想做的是合成少量的新特征。

随机梯度下降（stochastic gradient descent）可以用在在线学习上（online learning），而且步幅（学习率）对随机梯度下降法影响更大，需要谨慎选择。

如果在一个非常大的样本上训练模型，内存不够存，怎么做。使用随机梯度下降，把样本存在硬盘上，每次读一个例子。

为了克服随机梯度下降的缺点，可以使用mini-batch gradient descent（选择m个随机样本）

## 一、深度学习介绍（deep learning)