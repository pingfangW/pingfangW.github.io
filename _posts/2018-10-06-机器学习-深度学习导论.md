---
layout: post
title: "机器学习系列课程-深度学习导论"
description: "深度学习"
categories: [机器学习]
tags: [机器学习, 深度学习]
redirect_from:
  - /2018/10/23/
---

# 目录

* Kramdown table of contents
{:toc .toc}

# 正文

Advanced machine learning specialization 机器学习专业化进阶

## 一、线性模型

线性模型一般用于**回归**和**分类**

### 1.1 回归

![]({{ site.url }}/assets/images/machinelearning/linear_02.jpg){:height="50%" width="50%"}

如图所示，回归主要是完成对数据的拟合。

![]({{ site.url }}/assets/images/machinelearning/linear_03.jpg)

![]({{ site.url }}/assets/images/machinelearning/linear_04.jpg)

![]({{ site.url }}/assets/images/machinelearning/linear_05.jpg)


### 1.2 分类

![]({{ site.url }}/assets/images/machinelearning/linear_01.jpg){:height="50%" width="50%"}

如上图所示，用直线进行分类。

![]({{ site.url }}/assets/images/machinelearning/linear_06.jpg)

先通过似然函数，了解二项逻辑回归函数的来由。

![]({{ site.url }}/assets/images/machinelearning/linear_07.jpg)

![]({{ site.url }}/assets/images/machinelearning/linear_08.jpg)

![]({{ site.url }}/assets/images/machinelearning/linear_09.jpg)

![]({{ site.url }}/assets/images/machinelearning/linear_10.jpg)

![]({{ site.url }}/assets/images/machinelearning/linear_11.jpg)

### 1.3 梯度

了解各种梯度类型：

![]({{ site.url }}/assets/images/machinelearning/grad_01.jpg)

一般来说，梯度要计算所有样本的梯度值，因为损失函数就是各个样本的总和。  ==> gradient descent

但是在样本量很大的情况下，很难做到，这时候就采取近似梯度值的方法。

==> stochastic gradient descent ，好处是只需要一个样本，但是会产生很多噪声，但是迭代的次数足够多，可以收敛到一个最小点。而且可以应用到线上训练过程中，数据流不断产生新的数据，就用新的数据继续训练即可。
 
针对difficult function问题，采取 momentum 方法去改进梯度。

上图的4，作用是。一般梯度收敛是，如果是方向相同，即符号相同的时候，很快就会收敛到最小值。但是如果符号来回变动，就会一直徘徊，而4的改进方法是，如果前面一步和这一步的方向相同，那么会增加步幅，如果前面一步和这一步方向相反，则相互抵消，使得步幅几乎为0。

因此，ht消除了导致梯度震荡的一些坐标，使得实现更好更快的收敛。

对 momentum 方法改进的是 Nesterov momentum，这个算法里，我们计算现在这个点w_{t-1}的梯度值，我们从it走一梯度步gt，然后就得到了momentum

因为很显然，实际上就在沿着momentum的方向前进，因此更聪明的做法是，首先沿着ht的方向前进，然后在新点w_{t-1}上计算梯度，得到w_{t-1}+ht消除了导致梯度震荡的一些坐标，使得实现更好更快的收敛。

在这种情况下，我们可以得到在下一步上更好的估计。

但是上面的都是要求自己确定学习速率 eta_t，而 eta_t又会对结果产生很大的影响。

所以现在对学习速率进行改进，可以自动选择学习速率。

AdaGrad 分母加上epsilon只是为了不会除以0，这样把速率设置一个常数即可，后面就不用管了。
而且它对每个样本都选择自己的学习速率。 比如在文本分析中，每个字对应着一个特征，有的字经常出现，那么迭代的次数就会多一些，有的字不经常出现，那么迭代的次数就会少一些
缺点是G是积累，有时候会非常大，这样速率就变得很小，更新几乎就不动了。

所以改进上述的问题，就：

RMSprop加了权重，Adam对G进行了增强，转而使用V，之所以V分母增加了1-beta_2，是为了正则化，以抵消偏差（bias）的影响。在第一步，正则化（normalization还很大）
当t较大时，正则化就趋近于1。

但是momentum这个方法也有缺点。



x,y

回归和分类。均方误差，损失函数

在分类中的应用，y=-1,1

y = 1,2,...,k 多类

判断效果好坏：accuracy loss, Iverson bracket。其实就是看预测结果正确所占的比重。

但是这个指标有两个缺点：在优化过程中一般使用梯度去计算损失函数，而这个损失函数没有梯度，其次是无法计算置信度。

可以用损失函数替代 

a(x) = sign(w^Tx)

交叉熵（cross entropy）

二元/多元

梯度：

终止条件，既可以判断wt-1和wt之间的差是不是足够小，也可以判断损失函数的值的变化是不是变小，还有就是看梯度向量的模是不是接近于0.

有很多问题值得探讨，比如怎么去初始化w0，如何选择步幅eta_t，什么时候停止，如何去估计梯度。

什么情况下，线性模型的analytical solution和MSE loss有效：

训练集和测试集。

交叉训练（cross-validation)训练多次，但像深度神经网络在多个GPU上仍可能训练很多周，训练很多次是不太可行的，一般就选一个测试集。在数据量比较大的情况下，还是具有代表性的。

使用惩罚项的原因是：

在没有过度拟合的情况下，系数的数值一般会小一些。

因此把这个特点看做是特征，认为过度拟合的模型会有较大的权重，而好的模型没有较大的权重。

因此为了解决过度拟合问题，对大的权重进行惩罚。

这样总觉得不对，会不会导致前后结果差别很大？ 比如可能8次方的系数原先很大，然后惩罚以后8次方就被毙了，这种情况怎么说

这里主要是集中在在众多的特征中选择重要的特征。要和另外一种情况做区分：就是所有的特征都有用，想做的是合成少量的新特征。

随机梯度下降（stochastic gradient descent）可以用在在线学习上（online learning），而且步幅（学习率）对随机梯度下降法影响更大，需要谨慎选择。

如果在一个非常大的样本上训练模型，内存不够存，怎么做。使用随机梯度下降，把样本存在硬盘上，每次读一个例子。

为了克服随机梯度下降的缺点，可以使用mini-batch gradient descent（选择m个随机样本）

## 一、深度学习介绍（deep learning)