---
layout: post
title: "3. 循环神经网络"
description: "循环神经网络"
categories: [机器学习]
tags: [机器学习]
comments: true
---
# 目录：

* Kramdown table of contents
{:toc .toc}

循环神经网络RNN：
处理序列数据的神经网络


卷积网络可以很容易地扩展到具有很大宽度和高度的图像，以及处理 大小可变的图像，循环网络可以扩展到更长的序列(比不基于序列的特化网络长得 
多)。大多数循环网络也能处理可变长度的序列。 


从多层网络出发到循环网络，需要利用早期思想的优点:在模型的不同部分共享参数。
参数共享使得模型能够扩展到不同形式的样本(这里指不同长度的样本)并进行泛化。

如果我们在每个时间点都有 一个单独的参数，我们不但不能泛化到训练时没有见过序列长度，也不能在时间上 共享不同序列长度和不同位置的统计强度。当信息的特定部分会在序列内多个位置 出现时，这样的共享尤为重要。 

时延神经网络

卷积操作 允许网络跨时间共享参数，但是浅层的。卷积的输出是一个序列，其中输出中的每 一项是相邻几项输入的函数。 

参数共享的概念体现在：每个时间步中使用的相同卷积核。

循环神经网络以不同的方式共享参数 。

参数共享：每个时间步中使用相同卷积核。

循环神经网络以不同的方式共享参数：

输出的每一项是前一项的函数。
输出的每一项对先前的输出应用相同的更新规则而产生。
这种循环方式导致参数通过很深的计算图共享。

在实际情况中，循环网络通常在序列的小批量上操作，并 且小批量的每项具有不同序列长度 τ。 


展开计算图：

展开递归，循环计算

s(t) =f(s(t−1);θ), 

s(t) =f(s(t−1),x(t);θ),

本质上任何涉及循环的函数都可以被认为是一个循环神经网络。 

基于第 10.1 节中的图展开和参数共享的思想，我们可以设计各种循环神经网络。 

P326


# 一、




参考文献：

1. deep learning
