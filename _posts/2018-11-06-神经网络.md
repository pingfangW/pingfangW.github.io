---
layout: post
title: "神经网络"
description: "神经网络"
categories: [神经网络]
tags: [神经网络]
redirect_from:
  - /2018/10/23/
---

# 目录

* Kramdown table of contents
{:toc .toc}

# 正文

## 一、单一神经元网络

![]({{ site.url }}/assets/images/networks/onenetwork01.jpg)

一个神经元网络是最简单最基础的神经网络。

如上图所示：

输入是 $$x_1, x_2, x_3 和 截距 +1 $$

输出是 $$h_{x,b}(x)$$

中间的运算过程是 $$ f(W_1x_1 + W_2x_2 + W_3x_3)=f(W^Tx)=h_{W,b}(x) $$

这里的f(·)被称为激活函数。

这里激活函数选择sigmoid函数，公式如下：
$$ f(z) = \frac{1}{1+e^{-z}} $$


## 二、多个神经元网络

![]({{ site.url }}/assets/images/networks/network01.jpg)

神经网络就是将许多单一“神经元”联结在一起。

其中：

$$L_1$$是输入层，$$L_2$$是隐藏层，$$L_3$$是输出层。

参数：$$(W, b) = (W^{(1)}, b^{(1)}, W^{(2)}, b^{(2)})$$

$$ W^{(l)}_{ij} $$ 是 第l层第j单元 与 第 l+1层第i单元 之间的联结参数。
$$ b^{(l)}_{i} $$ 是 第l+1层第i单元的偏置项。

$$ a^{(l)}_{i} $$ 是 第l层第i大暖的激活值（输出值），那么：

$$ a^(1)_1 = x_1, a^(1)_2 = x_2, a^(1)_3 = x_3$$

$$ a^{(2)}_1 = f(W^{(1)}_{11}x_1 + W^{(1)}_{12}x_2 + W^{(1)}_{13}x_3 + b^{(1)}_1) $$
$$ a^{(2)}_2 = f(W^{(1)}_{21}x_1 + W^{(1)}_{22}x_2 + W^{(1)}_{23}x_3 + b^{(2)}_1) $$
$$ a^{(2)}_3 = f(W^{(1)}_{31}x_1 + W^{(1)}_{22}x_2 + W^{(1)}_{33}x_3 + b^{(3)}_1) $$

$$ h_{W,b}(x)= a^{(3)}_1 = f(W^{(2)}_{11}a^{(2)}_1 + W^{(2)}_{12}a^{(2)}_2 + W^{(2)}_{13}a^{(2)}_1 + b^{(2)}_1) $$

重新撰写是：

$$ z^{(l+1)} = W^{(l)}a^{(l)} + b^{(l)} $$
$$ a^{(l+1)} = f(z^{(l+1)}) $$

先计算第一层，再计算第二层，再计算第三层，依次计算，直到输出层。

这里依次向前计算，没有闭环或回路，被称为**前馈神经网络**。


## 三、多个输出单元

![]({{ site.url }}/assets/images/networks/network02.jpg)




参考文献：

http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C